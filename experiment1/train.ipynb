{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection.mask_rcnn import resnet50\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "from torcheval.metrics import MulticlassF1Score, MulticlassPrecision\n",
    "from torcheval.metrics.classification import MulticlassRecall\n",
    "from models import OnlineModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_recall, multiclass_precision, multiclass_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 132\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# CIFAR10 dataset split.\n",
    "dataset_train = datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    )\n",
    "dataset_train, dataset_val = random_split(dataset_train, [45000, 5000])\n",
    "dataset_test = datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    )\n",
    "    # Create data loaders.\n",
    "train_loader = DataLoader(\n",
    "        dataset_train, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "        dataset_val, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "test_loader = DataLoader(\n",
    "        dataset_test, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(multiclass_f1_score(torch.tensor([1, 1, 1, 1]), torch.tensor([0, 1, 1, 1]), num_classes=2, average=\"micro\").item())\n",
    "# print(multiclass_precision(torch.tensor([1, 1, 1, 1]), torch.tensor([0, 1, 1, 1]), num_classes=2, average=\"micro\").item())\n",
    "# print(multiclass_recall(torch.tensor([1, 1, 1, 1]), torch.tensor([0, 1, 1, 1]), num_classes=2, average=\"micro\").item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()\n",
    "model.fc = nn.Linear(in_features=2048, out_features=10, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 41.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.160, f1: 0.2029059614297931, p: 0.22636827637504273, r: 0.22446793235860263\n",
      "Validation loss: 1.939, f1: 0.29392848516765396, p: 0.30897745999850723, r: 0.3097578236146977\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 2 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 25.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 50.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.854, f1: 0.3189296936534367, p: 0.3480951831050632, r: 0.340619915216899\n",
      "Validation loss: 1.808, f1: 0.33772325986310053, p: 0.35967447961631577, r: 0.3596550390908593\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 3 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 25.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 50.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.690, f1: 0.375406042659038, p: 0.40277233151746283, r: 0.3964501596615811\n",
      "Validation loss: 1.722, f1: 0.372089811061558, p: 0.4018392131516808, r: 0.39422643498370524\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 4 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 25.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 48.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.556, f1: 0.42409037765869295, p: 0.44838714914238, r: 0.4435473195443755\n",
      "Validation loss: 1.624, f1: 0.40172286331653595, p: 0.4221214330510089, r: 0.42241808144669785\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 5 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 25.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 47.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.454, f1: 0.4642480275323314, p: 0.48884829660314966, r: 0.48264462061641505\n",
      "Validation loss: 1.547, f1: 0.41993111920984166, p: 0.454171979113629, r: 0.448409787918392\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 6 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 49.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.348, f1: 0.5043389805076409, p: 0.5260700152591526, r: 0.5225621636661966\n",
      "Validation loss: 1.525, f1: 0.44468695239016887, p: 0.46824101554720027, r: 0.45958794182852697\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 7 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 26.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 48.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.265, f1: 0.5364448082936474, p: 0.5574696200334431, r: 0.5533415780039477\n",
      "Validation loss: 1.499, f1: 0.45670212726843984, p: 0.468539906175513, r: 0.47138010043846934\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 8 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 26.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 48.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.167, f1: 0.5722026310183785, p: 0.5888978008650615, r: 0.5880960119434815\n",
      "Validation loss: 1.506, f1: 0.47703952146203893, p: 0.4876447500366914, r: 0.4899917699788746\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 9 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:13<00:00, 25.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 48.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.086, f1: 0.60226726488284, p: 0.6194304608879201, r: 0.6186515049151311\n",
      "Validation loss: 1.585, f1: 0.464857070069564, p: 0.4945778556560215, r: 0.4763180880170119\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 10 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:12<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 50.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.990, f1: 0.64002692681953, p: 0.6543057034791739, r: 0.6551058484661963\n",
      "Validation loss: 1.551, f1: 0.4724411486010802, p: 0.49175210297107697, r: 0.48280450936995056\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 11 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:12<00:00, 26.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 50.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.915, f1: 0.666286860568083, p: 0.6801112397325354, r: 0.6811666859210062\n",
      "Validation loss: 1.591, f1: 0.48884361433355433, p: 0.4999043086641713, r: 0.500759596103116\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 12 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:12<00:00, 26.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 51.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.838, f1: 0.6933437963385036, p: 0.7062799093310784, r: 0.70750704766019\n",
      "Validation loss: 1.618, f1: 0.4763316661119461, p: 0.49766919644255386, r: 0.4832678719570762\n",
      "--------------------------------------------------\n",
      "TRAINING COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# f1_metric = MulticlassF1Score(num_classes=10)\n",
    "# p_metric = MulticlassPrecision(num_classes=10)\n",
    "# r_metric = MulticlassRecall(num_classes=10)\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "f1_train, f1_valid = [], []\n",
    "p_train, p_valid = [], []\n",
    "r_train, r_valid = [], []\n",
    "\n",
    "# Start the training.\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "\n",
    "    print('Training')\n",
    "    train_epoch_loss = 0.0\n",
    "    counter = 0\n",
    "    train_f1 = 0.0\n",
    "    train_p = 0.0\n",
    "    train_r = 0.0\n",
    "    for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        counter += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # f1_metric.update(outputs, labels)\n",
    "        # p_metric.update(outputs, labels)\n",
    "        # r_metric.update(outputs, labels)\n",
    "        # train_f1 += f1_metric.compute().item()\n",
    "        # train_p += p_metric.compute().item()\n",
    "        # train_r += r_metric.compute().item()\n",
    "        train_f1 += multiclass_f1_score(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        train_p += multiclass_precision(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        train_r += multiclass_recall(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "    train_epoch_loss = train_epoch_loss / counter\n",
    "    train_f1 = train_f1 / counter\n",
    "    train_p = train_p / counter\n",
    "    train_r = train_r / counter\n",
    "\n",
    "    model.eval()\n",
    "    print(\"Validation\")\n",
    "    valid_epoch_loss = 0\n",
    "    counter = 0\n",
    "    val_f1 = 0.0\n",
    "    val_p = 0.0\n",
    "    val_r = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "            counter += 1\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # f1_metric.update(outputs, labels)\n",
    "            # p_metric.update(outputs, labels)\n",
    "            # r_metric.update(outputs, labels)\n",
    "            val_f1 += multiclass_f1_score(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            val_p += multiclass_precision(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            val_r += multiclass_recall(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            # print statistics\n",
    "            valid_epoch_loss += loss.item()\n",
    "\n",
    "    valid_epoch_loss = valid_epoch_loss / counter\n",
    "    val_f1 = val_f1 / counter\n",
    "    val_p = val_p / counter\n",
    "    val_r = val_r / counter\n",
    "\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "\n",
    "    f1_train.append(train_f1)\n",
    "    f1_valid.append(val_f1)\n",
    "\n",
    "    p_train.append(train_p)\n",
    "    p_valid.append(val_p)\n",
    "\n",
    "    r_train.append(train_r)\n",
    "    r_valid.append(val_r)\n",
    "\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, f1: {train_f1}, p: {train_p}, r: {train_r}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, f1: {val_f1}, p: {val_p}, r: {val_r}\")\n",
    "    print('-'*50)\n",
    "        \n",
    "print('TRAINING COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./weights/base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OnlineModel().encoder\n",
    "model.load_state_dict(torch.load(\"../BYOL/pretrained_feature_extractors/feature_extractor_20\"))\n",
    "model.fc = nn.Linear(in_features=2048, out_features=10, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze all layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze last layer\n",
    "# for param in model.fc.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:45<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 19.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.334, f1: 0.055799128378460135, p: 0.06313767095978572, r: 0.12487802776860352\n",
      "Validation loss: 2.380, f1: 0.06332263698507297, p: 0.057490208921463865, r: 0.1346162732102369\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 2 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:44<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.300, f1: 0.0761635543893247, p: 0.08386690702147323, r: 0.14603866507842744\n",
      "Validation loss: 2.271, f1: 0.06752822729513834, p: 0.08216146284126137, r: 0.15840311799394458\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 3 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:45<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 19.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.279, f1: 0.08955873857058388, p: 0.09652604766823679, r: 0.15659440407130726\n",
      "Validation loss: 2.300, f1: 0.09284839534053677, p: 0.08163645677268505, r: 0.16530683107281985\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 4 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:44<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.251, f1: 0.09877555280967541, p: 0.10928929058010103, r: 0.1610668741406933\n",
      "Validation loss: 2.377, f1: 0.09876088366696709, p: 0.0859151927656249, r: 0.1741296370562754\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 5 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:44<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.240, f1: 0.1076941308387913, p: 0.11490007932366164, r: 0.1700982015547165\n",
      "Validation loss: 2.323, f1: 0.10828044736071636, p: 0.13184672829351926, r: 0.1677242715499903\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 6 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:44<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 20.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.236, f1: 0.10929248354171028, p: 0.12038027163584036, r: 0.172061949968338\n",
      "Validation loss: 2.244, f1: 0.12401773270807769, p: 0.11132986843585968, r: 0.18175539276317546\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 7 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:44<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.231, f1: 0.11265094884701314, p: 0.12330422542792611, r: 0.1752409615780601\n",
      "Validation loss: 2.216, f1: 0.11401189667613883, p: 0.10282595828175545, r: 0.1806074404402783\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 8 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:43<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 20.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.211, f1: 0.11753976642211511, p: 0.12863790889508214, r: 0.18165116516813154\n",
      "Validation loss: 2.181, f1: 0.10980267018864029, p: 0.1249152835654585, r: 0.16980401348126561\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 9 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:45<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 19.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.192, f1: 0.125351970092205, p: 0.13759354331538823, r: 0.1853097205724884\n",
      "Validation loss: 2.184, f1: 0.13567283239803815, p: 0.11849062242790272, r: 0.18477229146580948\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 10 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:44<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 20.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.187, f1: 0.12290377280185999, p: 0.133584844445553, r: 0.18521007849586324\n",
      "Validation loss: 2.222, f1: 0.12207499244495441, p: 0.13700973762101248, r: 0.18571655216969943\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 11 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:44<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 20.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.178, f1: 0.12939596449262586, p: 0.14287980223112792, r: 0.18852837700560646\n",
      "Validation loss: 2.191, f1: 0.12217146001364056, p: 0.12641450498057039, r: 0.18444752065758957\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 12 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:44<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 19.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.182, f1: 0.1288635454023164, p: 0.13980741245000244, r: 0.19021832956072174\n",
      "Validation loss: 2.188, f1: 0.13237648692570234, p: 0.12137670138556707, r: 0.19988089721453817\n",
      "--------------------------------------------------\n",
      "TRAINING COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_pretrained, valid_loss_pretrained = [], []\n",
    "f1_train_pretrained, f1_valid_pretrained = [], []\n",
    "p_train_pretrained, p_valid_pretrained = [], []\n",
    "r_train_pretrained, r_valid_pretrained = [], []\n",
    "\n",
    "# Start the training.\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "\n",
    "    print('Training')\n",
    "    train_epoch_loss = 0.0\n",
    "    counter = 0\n",
    "    train_f1 = 0.0\n",
    "    train_p = 0.0\n",
    "    train_r = 0.0\n",
    "    for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        counter += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # f1_metric.update(outputs, labels)\n",
    "        # p_metric.update(outputs, labels)\n",
    "        # r_metric.update(outputs, labels)\n",
    "        train_f1 += multiclass_f1_score(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        train_p += multiclass_precision(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        train_r += multiclass_recall(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "    train_epoch_loss = train_epoch_loss / counter\n",
    "    train_f1 = train_f1 / counter\n",
    "    train_p = train_p / counter\n",
    "    train_r = train_r / counter\n",
    "\n",
    "    model.eval()\n",
    "    print(\"Validation\")\n",
    "    valid_epoch_loss = 0\n",
    "    counter = 0\n",
    "    val_f1 = 0.0\n",
    "    val_p = 0.0\n",
    "    val_r = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "            counter += 1\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # f1_metric.update(outputs, labels)\n",
    "            # p_metric.update(outputs, labels)\n",
    "            # r_metric.update(outputs, labels)\n",
    "            val_f1 += multiclass_f1_score(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            val_p += multiclass_precision(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            val_r += multiclass_recall(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            # print statistics\n",
    "            valid_epoch_loss += loss.item()\n",
    "\n",
    "    valid_epoch_loss = valid_epoch_loss / counter\n",
    "    val_f1 = val_f1 / counter\n",
    "    val_p = val_p / counter\n",
    "    val_r = val_r / counter\n",
    "\n",
    "    train_loss_pretrained.append(train_epoch_loss)\n",
    "    valid_loss_pretrained.append(valid_epoch_loss)\n",
    "\n",
    "    f1_train_pretrained.append(train_f1)\n",
    "    f1_valid_pretrained.append(val_f1)\n",
    "\n",
    "    p_train_pretrained.append(train_p)\n",
    "    p_valid_pretrained.append(val_p)\n",
    "\n",
    "    r_train_pretrained.append(train_r)\n",
    "    r_valid_pretrained.append(val_r)\n",
    "\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, f1: {train_f1}, p: {train_p}, r: {train_r}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, f1: {val_f1}, p: {val_p}, r: {val_r}\")\n",
    "    print('-'*50)\n",
    "        \n",
    "print('TRAINING COMPLETE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./weights/pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f1_train_pretrained, label='f1_train_pretrained')\n",
    "plt.plot(f1_valid_pretrained, label='f1_valid_pretrained')\n",
    "plt.plot(f1_train, label='f1_train')\n",
    "plt.plot(f1_valid, label='f1_valid')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"./plots/f1\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(p_train_pretrained, label='p_train_pretrained')\n",
    "plt.plot(p_valid_pretrained, label='p_valid_pretrained')\n",
    "plt.plot(p_train, label='p_train')\n",
    "plt.plot(p_valid, label='p_valid')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"./plots/precision\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r_train_pretrained, label='r_train_pretrained')\n",
    "plt.plot(r_valid_pretrained, label='r_valid_pretrained')\n",
    "plt.plot(r_train, label='r_train')\n",
    "plt.plot(r_valid, label='r_valid')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"./plots/recall\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_pretrained, label='train_loss_pretrained')\n",
    "plt.plot(valid_loss_pretrained, label='train_loss_pretrained')\n",
    "plt.plot(train_loss, label='train_loss')\n",
    "plt.plot(valid_loss, label='train_loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"./plots/loss\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

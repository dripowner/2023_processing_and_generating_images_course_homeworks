{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection.mask_rcnn import resnet50\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "from torcheval.metrics import MulticlassF1Score, MulticlassPrecision\n",
    "from torcheval.metrics.classification import MulticlassRecall\n",
    "from models import OnlineModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_recall, multiclass_precision, multiclass_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# CIFAR10 dataset split.\n",
    "dataset_train = datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    )\n",
    "dataset_train, dataset_val = random_split(dataset_train, [45000, 5000])\n",
    "dataset_train, _ = random_split(dataset_train, [4500, 40500])\n",
    "dataset_val, _ = random_split(dataset_val, [500, 4500])\n",
    "dataset_test = datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    )\n",
    "    # Create data loaders.\n",
    "train_loader = DataLoader(\n",
    "        dataset_train, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "        dataset_val, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "test_loader = DataLoader(\n",
    "        dataset_test, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(multiclass_f1_score(torch.tensor([1, 1, 1, 1]), torch.tensor([0, 1, 1, 1]), num_classes=2, average=\"micro\").item())\n",
    "# print(multiclass_precision(torch.tensor([1, 1, 1, 1]), torch.tensor([0, 1, 1, 1]), num_classes=2, average=\"micro\").item())\n",
    "# print(multiclass_recall(torch.tensor([1, 1, 1, 1]), torch.tensor([0, 1, 1, 1]), num_classes=2, average=\"micro\").item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()\n",
    "model.fc = nn.Linear(in_features=2048, out_features=10, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.490, f1: 0.0953126907762554, p: 0.10864415475063854, r: 0.10919060930609703\n",
      "Validation loss: 2.351, f1: 0.07910642400383949, p: 0.12404929473996162, r: 0.12152556329965591\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 2 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 28.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.410, f1: 0.12094948068261147, p: 0.1308628941575686, r: 0.13322563469409943\n",
      "Validation loss: 2.566, f1: 0.0999944917857647, p: 0.11440722271800041, r: 0.10855479165911674\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 3 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 24.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.336, f1: 0.13070274227195317, p: 0.1452573649585247, r: 0.14140580718715987\n",
      "Validation loss: 2.587, f1: 0.12642822787165642, p: 0.13679759204387665, r: 0.1373981609940529\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 4 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.285, f1: 0.1492091491818428, p: 0.16416835660735765, r: 0.16430271913607916\n",
      "Validation loss: 2.395, f1: 0.14403236284852028, p: 0.1511385515332222, r: 0.16208580136299133\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 5 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 27.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.205, f1: 0.18487298819753858, p: 0.1999764997098181, r: 0.19692341403828728\n",
      "Validation loss: 2.333, f1: 0.16199962049722672, p: 0.17115431278944016, r: 0.16771823912858963\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 6 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 26.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.149, f1: 0.2103632026248508, p: 0.23148226075702244, r: 0.22391275068124136\n",
      "Validation loss: 2.217, f1: 0.1705378219485283, p: 0.19318005442619324, r: 0.18301738798618317\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 7 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.095, f1: 0.23392324232392842, p: 0.2590810689661238, r: 0.2461659461259842\n",
      "Validation loss: 2.219, f1: 0.19656091928482056, p: 0.21177832037210464, r: 0.22755196690559387\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 8 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 28.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.028, f1: 0.2485276891125573, p: 0.27964261919260025, r: 0.2660578638315201\n",
      "Validation loss: 2.222, f1: 0.18936192989349365, p: 0.20658008754253387, r: 0.20716143399477005\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 9 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 17.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 26.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.957, f1: 0.2891757935285568, p: 0.3093995617495643, r: 0.300629672076967\n",
      "Validation loss: 2.187, f1: 0.1873161941766739, p: 0.20093470811843872, r: 0.20845971256494522\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 10 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.889, f1: 0.3140010353591707, p: 0.336570594045851, r: 0.3283900287416246\n",
      "Validation loss: 2.172, f1: 0.21691153198480606, p: 0.2256055846810341, r: 0.23205406218767166\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 11 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 28.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.824, f1: 0.3361483845445845, p: 0.3733382026354472, r: 0.35214420325226253\n",
      "Validation loss: 2.143, f1: 0.22893569618463516, p: 0.23847205191850662, r: 0.23860371112823486\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 12 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 17.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 26.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.764, f1: 0.3517172535260518, p: 0.37306736409664154, r: 0.36469634705119663\n",
      "Validation loss: 2.142, f1: 0.23503126949071884, p: 0.25170814990997314, r: 0.2553534358739853\n",
      "--------------------------------------------------\n",
      "TRAINING COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# f1_metric = MulticlassF1Score(num_classes=10)\n",
    "# p_metric = MulticlassPrecision(num_classes=10)\n",
    "# r_metric = MulticlassRecall(num_classes=10)\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "f1_train, f1_valid = [], []\n",
    "p_train, p_valid = [], []\n",
    "r_train, r_valid = [], []\n",
    "\n",
    "# Start the training.\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "\n",
    "    print('Training')\n",
    "    train_epoch_loss = 0.0\n",
    "    counter = 0\n",
    "    train_f1 = 0.0\n",
    "    train_p = 0.0\n",
    "    train_r = 0.0\n",
    "    for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        counter += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # f1_metric.update(outputs, labels)\n",
    "        # p_metric.update(outputs, labels)\n",
    "        # r_metric.update(outputs, labels)\n",
    "        # train_f1 += f1_metric.compute().item()\n",
    "        # train_p += p_metric.compute().item()\n",
    "        # train_r += r_metric.compute().item()\n",
    "        train_f1 += multiclass_f1_score(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        train_p += multiclass_precision(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        train_r += multiclass_recall(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "    train_epoch_loss = train_epoch_loss / counter\n",
    "    train_f1 = train_f1 / counter\n",
    "    train_p = train_p / counter\n",
    "    train_r = train_r / counter\n",
    "\n",
    "    model.eval()\n",
    "    print(\"Validation\")\n",
    "    valid_epoch_loss = 0\n",
    "    counter = 0\n",
    "    val_f1 = 0.0\n",
    "    val_p = 0.0\n",
    "    val_r = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "            counter += 1\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # f1_metric.update(outputs, labels)\n",
    "            # p_metric.update(outputs, labels)\n",
    "            # r_metric.update(outputs, labels)\n",
    "            val_f1 += multiclass_f1_score(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            val_p += multiclass_precision(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            val_r += multiclass_recall(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            # print statistics\n",
    "            valid_epoch_loss += loss.item()\n",
    "\n",
    "    valid_epoch_loss = valid_epoch_loss / counter\n",
    "    val_f1 = val_f1 / counter\n",
    "    val_p = val_p / counter\n",
    "    val_r = val_r / counter\n",
    "\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "\n",
    "    f1_train.append(train_f1)\n",
    "    f1_valid.append(val_f1)\n",
    "\n",
    "    p_train.append(train_p)\n",
    "    p_valid.append(val_p)\n",
    "\n",
    "    r_train.append(train_r)\n",
    "    r_valid.append(val_r)\n",
    "\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, f1: {train_f1}, p: {train_p}, r: {train_r}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, f1: {val_f1}, p: {val_p}, r: {val_r}\")\n",
    "    print('-'*50)\n",
    "        \n",
    "print('TRAINING COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./weights/base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OnlineModel().encoder\n",
    "model.load_state_dict(torch.load(\"../BYOL/pretrained_feature_extractors/feature_extractor_20\"))\n",
    "model.fc = nn.Linear(in_features=2048, out_features=10, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze all layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze last layer\n",
    "# for param in model.fc.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Epoch 1 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.357, f1: 0.04024852791594134, p: 0.04881262000546687, r: 0.10775816233621703\n",
      "Validation loss: 2.399, f1: 0.040535902604460716, p: 0.04894971288740635, r: 0.10632399842143059\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 2 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.347, f1: 0.0463479385814733, p: 0.05908137347756161, r: 0.11810547113418579\n",
      "Validation loss: 2.353, f1: 0.059190401807427406, p: 0.06246899627149105, r: 0.1228143647313118\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 3 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.303, f1: 0.05979946214291784, p: 0.08910970480388238, r: 0.12106376265486081\n",
      "Validation loss: 2.328, f1: 0.06216698698699474, p: 0.05312344804406166, r: 0.12902161106467247\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 4 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.310, f1: 0.0550220383124219, p: 0.07064732660849889, r: 0.12648924440145493\n",
      "Validation loss: 2.346, f1: 0.05432921648025513, p: 0.0884223710745573, r: 0.11786853522062302\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 5 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.301, f1: 0.06044065631512138, p: 0.09038944195749031, r: 0.12818620436721379\n",
      "Validation loss: 2.308, f1: 0.05009664595127106, p: 0.04569598566740751, r: 0.13499633222818375\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 6 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.294, f1: 0.07221663350032435, p: 0.09643986769434479, r: 0.13879791647195816\n",
      "Validation loss: 2.310, f1: 0.06164790131151676, p: 0.04557429999113083, r: 0.13034038618206978\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 7 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.319, f1: 0.06086772581976321, p: 0.07021175681923826, r: 0.12774895835253927\n",
      "Validation loss: 2.321, f1: 0.01680778292939067, p: 0.009282146580517292, r: 0.10000000149011612\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 8 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.312, f1: 0.07033487181696627, p: 0.08284056525573963, r: 0.13837124821212557\n",
      "Validation loss: 2.337, f1: 0.06424254179000854, p: 0.05818105861544609, r: 0.12228836864233017\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 9 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.311, f1: 0.07585275338755713, p: 0.09132749038851923, r: 0.1376114942961269\n",
      "Validation loss: 2.331, f1: 0.05191346816718578, p: 0.04798607528209686, r: 0.12351730093359947\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 10 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.292, f1: 0.07315021339390013, p: 0.10450689122080803, r: 0.14365431583589977\n",
      "Validation loss: 2.332, f1: 0.06460334733128548, p: 0.061460599303245544, r: 0.13246093317866325\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 11 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.309, f1: 0.0628015057494243, p: 0.07648795605119732, r: 0.13573211638463867\n",
      "Validation loss: 2.357, f1: 0.05098233371973038, p: 0.06255516409873962, r: 0.11834509670734406\n",
      "--------------------------------------------------\n",
      "[INFO]: Epoch 12 of 12\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.288, f1: 0.06886826517681281, p: 0.09209533677332932, r: 0.13297979409495989\n",
      "Validation loss: 2.309, f1: 0.06492675840854645, p: 0.0791527982801199, r: 0.12506486102938652\n",
      "--------------------------------------------------\n",
      "TRAINING COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_pretrained, valid_loss_pretrained = [], []\n",
    "f1_train_pretrained, f1_valid_pretrained = [], []\n",
    "p_train_pretrained, p_valid_pretrained = [], []\n",
    "r_train_pretrained, r_valid_pretrained = [], []\n",
    "\n",
    "# Start the training.\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "\n",
    "    print('Training')\n",
    "    train_epoch_loss = 0.0\n",
    "    counter = 0\n",
    "    train_f1 = 0.0\n",
    "    train_p = 0.0\n",
    "    train_r = 0.0\n",
    "    for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        counter += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # f1_metric.update(outputs, labels)\n",
    "        # p_metric.update(outputs, labels)\n",
    "        # r_metric.update(outputs, labels)\n",
    "        train_f1 += multiclass_f1_score(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        train_p += multiclass_precision(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        train_r += multiclass_recall(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "    train_epoch_loss = train_epoch_loss / counter\n",
    "    train_f1 = train_f1 / counter\n",
    "    train_p = train_p / counter\n",
    "    train_r = train_r / counter\n",
    "\n",
    "    model.eval()\n",
    "    print(\"Validation\")\n",
    "    valid_epoch_loss = 0\n",
    "    counter = 0\n",
    "    val_f1 = 0.0\n",
    "    val_p = 0.0\n",
    "    val_r = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "            counter += 1\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # f1_metric.update(outputs, labels)\n",
    "            # p_metric.update(outputs, labels)\n",
    "            # r_metric.update(outputs, labels)\n",
    "            val_f1 += multiclass_f1_score(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            val_p += multiclass_precision(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            val_r += multiclass_recall(outputs, labels, num_classes=10, average=\"macro\").item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            # print statistics\n",
    "            valid_epoch_loss += loss.item()\n",
    "\n",
    "    valid_epoch_loss = valid_epoch_loss / counter\n",
    "    val_f1 = val_f1 / counter\n",
    "    val_p = val_p / counter\n",
    "    val_r = val_r / counter\n",
    "\n",
    "    train_loss_pretrained.append(train_epoch_loss)\n",
    "    valid_loss_pretrained.append(valid_epoch_loss)\n",
    "\n",
    "    f1_train_pretrained.append(train_f1)\n",
    "    f1_valid_pretrained.append(val_f1)\n",
    "\n",
    "    p_train_pretrained.append(train_p)\n",
    "    p_valid_pretrained.append(val_p)\n",
    "\n",
    "    r_train_pretrained.append(train_r)\n",
    "    r_valid_pretrained.append(val_r)\n",
    "\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, f1: {train_f1}, p: {train_p}, r: {train_r}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, f1: {val_f1}, p: {val_p}, r: {val_r}\")\n",
    "    print('-'*50)\n",
    "        \n",
    "print('TRAINING COMPLETE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./weights/pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f1_train_pretrained, label='f1_train_pretrained')\n",
    "plt.plot(f1_valid_pretrained, label='f1_valid_pretrained')\n",
    "plt.plot(f1_train, label='f1_train')\n",
    "plt.plot(f1_valid, label='f1_valid')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"./plots/f1\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(p_train_pretrained, label='p_train_pretrained')\n",
    "plt.plot(p_valid_pretrained, label='p_valid_pretrained')\n",
    "plt.plot(p_train, label='p_train')\n",
    "plt.plot(p_valid, label='p_valid')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"./plots/precision\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r_train_pretrained, label='r_train_pretrained')\n",
    "plt.plot(r_valid_pretrained, label='r_valid_pretrained')\n",
    "plt.plot(r_train, label='r_train')\n",
    "plt.plot(r_valid, label='r_valid')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"./plots/recall\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_pretrained, label='train_loss_pretrained')\n",
    "plt.plot(valid_loss_pretrained, label='train_loss_pretrained')\n",
    "plt.plot(train_loss, label='train_loss')\n",
    "plt.plot(valid_loss, label='train_loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f\"./plots/loss\", bbox_inches='tight')\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

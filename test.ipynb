{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 32.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики: Precesion - 71.54, Recall - 71.49, F1 - 71.44\n",
      "\n",
      "Метрики для plane: Precesion - 72.54, Recall - 72.58, F1 - 72.52\n",
      "\n",
      "Метрики для car: Precesion - 74.36, Recall - 72.84, F1 - 73.55\n",
      "\n",
      "Метрики для bird: Precesion - 68.08, Recall - 70.61, F1 - 69.27\n",
      "\n",
      "Метрики для cat: Precesion - 70.00, Recall - 69.15, F1 - 69.51\n",
      "\n",
      "Метрики для deer: Precesion - 72.51, Recall - 69.16, F1 - 70.73\n",
      "\n",
      "Метрики для dog: Precesion - 70.12, Recall - 70.68, F1 - 70.33\n",
      "\n",
      "Метрики для frog: Precesion - 74.49, Recall - 71.04, F1 - 72.69\n",
      "\n",
      "Метрики для horse: Precesion - 68.70, Recall - 72.73, F1 - 70.59\n",
      "\n",
      "Метрики для ship: Precesion - 74.51, Recall - 72.74, F1 - 73.57\n",
      "\n",
      "Метрики для truck: Precesion - 70.08, Recall - 73.38, F1 - 71.64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data_utils import get_dataloaders\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.detection.mask_rcnn import resnet50\n",
    "from utils import precision, recall, f1_score\n",
    "\n",
    "\n",
    "# open config file\n",
    "with open('config.json') as f:\n",
    "    config = json.load(f) \n",
    "\n",
    "batch_size = config[\"batch_size\"]\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model = resnet50().to(device)\n",
    "model.load_state_dict(torch.load(\"./results/runs/2024-01-09_16_58_34_927901/model\"))\n",
    "\n",
    "_, _, test_loader = get_dataloaders(batch_size)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "p = 0\n",
    "r = 0\n",
    "f1 = 0\n",
    "p_classes, r_classes, f1_classes = [0]*10, [0]*10, [0]*10\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            for class_id in range(10):\n",
    "                if precision(outputs, labels, class_id) is not None:\n",
    "                    p_classes[class_id] += precision(outputs, labels, class_id)\n",
    "                else:\n",
    "                    p_classes[class_id] += 0\n",
    "                \n",
    "                if recall(outputs, labels, class_id) is not None:\n",
    "                    r_classes[class_id] += recall(outputs, labels, class_id)\n",
    "                else:\n",
    "                    r_classes[class_id] += 0\n",
    "\n",
    "                if f1_score(outputs, labels, class_id) is not None:\n",
    "                    f1_classes[class_id] += f1_score(outputs, labels, class_id)\n",
    "                else:\n",
    "                    f1_classes[class_id] += 0\n",
    "\n",
    "        p = sum(p_classes) / len(p_classes)\n",
    "        r = sum(r_classes) / len(r_classes)\n",
    "        f1 = sum(f1_classes) / len(f1_classes)\n",
    "\n",
    "print(f\"Метрики: Precesion - {p:.2f}, Recall - {r:.2f}, F1 - {f1:.2f}\\n\")\n",
    "for class_id in range(len(classes)):\n",
    "    print(f\"Метрики для {classes[class_id]}: Precesion - {p_classes[class_id]:.2f}, Recall - {r_classes[class_id]:.2f}, F1 - {f1_classes[class_id]:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 35.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики: Precesion - 72.48, Recall - 72.45, F1 - 72.42\n",
      "\n",
      "Метрики для plane: Precesion - 73.37, Recall - 73.32, F1 - 73.31\n",
      "\n",
      "Метрики для car: Precesion - 75.03, Recall - 73.45, F1 - 74.20\n",
      "\n",
      "Метрики для bird: Precesion - 68.66, Recall - 71.66, F1 - 70.09\n",
      "\n",
      "Метрики для cat: Precesion - 71.19, Recall - 70.10, F1 - 70.60\n",
      "\n",
      "Метрики для deer: Precesion - 70.35, Recall - 71.86, F1 - 71.06\n",
      "\n",
      "Метрики для dog: Precesion - 72.03, Recall - 71.29, F1 - 71.61\n",
      "\n",
      "Метрики для frog: Precesion - 73.47, Recall - 73.40, F1 - 73.40\n",
      "\n",
      "Метрики для horse: Precesion - 74.94, Recall - 71.95, F1 - 73.37\n",
      "\n",
      "Метрики для ship: Precesion - 72.62, Recall - 74.24, F1 - 73.39\n",
      "\n",
      "Метрики для truck: Precesion - 73.11, Recall - 73.26, F1 - 73.14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./results/runs/2024-01-09_17_04_46_222598/model\"))\n",
    "\n",
    "_, _, test_loader = get_dataloaders(batch_size)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "p = 0\n",
    "r = 0\n",
    "f1 = 0\n",
    "p_classes, r_classes, f1_classes = [0]*10, [0]*10, [0]*10\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            for class_id in range(10):\n",
    "                if precision(outputs, labels, class_id) is not None:\n",
    "                    p_classes[class_id] += precision(outputs, labels, class_id)\n",
    "                else:\n",
    "                    p_classes[class_id] += 0\n",
    "                \n",
    "                if recall(outputs, labels, class_id) is not None:\n",
    "                    r_classes[class_id] += recall(outputs, labels, class_id)\n",
    "                else:\n",
    "                    r_classes[class_id] += 0\n",
    "\n",
    "                if f1_score(outputs, labels, class_id) is not None:\n",
    "                    f1_classes[class_id] += f1_score(outputs, labels, class_id)\n",
    "                else:\n",
    "                    f1_classes[class_id] += 0\n",
    "\n",
    "        p = sum(p_classes) / len(p_classes)\n",
    "        r = sum(r_classes) / len(r_classes)\n",
    "        f1 = sum(f1_classes) / len(f1_classes)\n",
    "\n",
    "print(f\"Метрики: Precesion - {p:.2f}, Recall - {r:.2f}, F1 - {f1:.2f}\\n\")\n",
    "for class_id in range(len(classes)):\n",
    "    print(f\"Метрики для {classes[class_id]}: Precesion - {p_classes[class_id]:.2f}, Recall - {r_classes[class_id]:.2f}, F1 - {f1_classes[class_id]:.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
